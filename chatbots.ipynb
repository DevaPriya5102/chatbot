{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "groq_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000002BFF05C8190>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000002BFF1A6D7B0>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model = ChatGroq(model=\"gemma2-9b-it\",groq_api_key=groq_api_key)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Deva! It's great to meet you. \\n\\nThat's fantastic! Data Science is a really exciting field. What are you focusing on in your master's program? Do you have any particular areas of interest within data science? \\n\\nI'm always eager to learn more about what people are working on in this field.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 73, 'prompt_tokens': 26, 'total_tokens': 99, 'completion_time': 0.132727273, 'prompt_time': 0.000136259, 'queue_time': 0.019134649, 'total_time': 0.132863532}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-bba062a9-64ce-48d9-aecb-f08afeebd358-0', usage_metadata={'input_tokens': 26, 'output_tokens': 73, 'total_tokens': 99})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "model.invoke([HumanMessage(content=\"Hi, My name is Deva. I am a master's student in Data Science\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You told me your name is Deva and that you are a master's student in Data Science! üòä  Is there anything else you'd like to tell me about yourself or your studies? \\n\\nI'm eager to learn more.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 52, 'prompt_tokens': 60, 'total_tokens': 112, 'completion_time': 0.094545455, 'prompt_time': 0.001828962, 'queue_time': 0.020445156, 'total_time': 0.096374417}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-f8a55329-e593-47d6-8856-fbb7f9c13f6c-0', usage_metadata={'input_tokens': 60, 'output_tokens': 52, 'total_tokens': 112})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi, My name is Deva. I am a master's student in Data Science\"),\n",
    "        AIMessage(content=\"Hi Deva! It's great to meet you.\"),\n",
    "        HumanMessage(content=\"Hey, what's my name and what do I do?\")\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## message history\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store={}\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(model,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello Deva, it's nice to meet you! üëã  \\n\\nWhat can I do for you today? üòä\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 26, 'prompt_tokens': 16, 'total_tokens': 42, 'completion_time': 0.047272727, 'prompt_time': 0.000109749, 'queue_time': 0.021831071, 'total_time': 0.047382476}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-fd7d5a30-c009-4f21-a55f-d61144d61a9c-0', usage_metadata={'input_tokens': 16, 'output_tokens': 26, 'total_tokens': 42})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi, My name is Deva.\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I'm starting to think this is a fun game! üòÑ\\n\\nYour name is Deva.  \\n\\nIs there anything else you'd like to ask or talk about?  \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 39, 'prompt_tokens': 187, 'total_tokens': 226, 'completion_time': 0.070909091, 'prompt_time': 0.005772874, 'queue_time': 0.023146702999999998, 'total_time': 0.076681965}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-80410b1c-0a40-45b7-9b80-8b4052f9f84b-0', usage_metadata={'input_tokens': 187, 'output_tokens': 39, 'total_tokens': 226})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name?\")],\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, Deva, I get it!  You're really enjoying this.  \\n\\nYour name is Deva.  \\n\\nDo you have any other riddles for me? üòú  \\n\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## change the config -> session_id\n",
    "config1={\"configurable\":{\"session_id\":\"chat3\"}}\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name?\")],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"That's a great question!  \\n\\nAs a large language model, I don't actually have memory of past conversations or user information like names. Every time we start a new conversation, it's like a fresh start. \\n\\nWhen you said your name was Deva, I stored that information *within the context of our current conversation*. So, even if the session ID changed, I would remember your name as long as we kept talking.  \\n\\nThink of it like having a notepad. Each time we chat, it's a new page. If you write your name on that page, I'll remember it for that conversation. But if we close the notepad and start a new one, I'd forget until you wrote your name again. \\n\\n\\n\\nLet me know if you have any other questions!\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"How can you remember my name when i changed the session_id?\")],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful assistant. Answer all the questions to the nest of your ability\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain=prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi there! It's great to meet you.  \\n\\nAs a data science master's student, I'm sure you have lots of interesting projects and questions. How can I help you today?  \\n\\nI can assist with:\\n\\n* **Explaining data science concepts:** If you're stuck on a particular topic, I can try to explain it in a clear and concise way.\\n* **Generating code snippets:** I can provide examples of code in various programming languages commonly used in data science, such as Python and R.\\n* **Brainstorming ideas:** Need help coming up with a new project or approach to a problem? I can help you brainstorm ideas.\\n* **Discussing research papers:**  \\nIf you've read a paper and want to discuss it, I'm happy to offer my insights.\\n\\nJust let me know what you need! üòä\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 184, 'prompt_tokens': 37, 'total_tokens': 221, 'completion_time': 0.334545455, 'prompt_time': 0.000697237, 'queue_time': 0.028117363, 'total_time': 0.335242692}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-4ca78d14-5fbb-483f-ae1d-9bc868b7b8bf-0', usage_metadata={'input_tokens': 37, 'output_tokens': 184, 'total_tokens': 221})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\":[HumanMessage(content=\"Hi! I am a data science master's student.\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(chain,get_session_history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As a large language model, I have no memory of past conversations and do not know your name. üòä  \\n\\nIf you'd like to tell me your name, I'd be happy to use it!\\n\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\":{\"session_id\":\"chat4\"}}\n",
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name?\")],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add more complexity\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful assistant. Answer all the questions to the nest of your ability in {language}\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain=prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡∞®‡∞æ‡∞ï‡±Å ‡∞§‡±Ü‡∞≤‡±Å‡∞ó‡±Å‡∞≤‡±ã ‡∞∏‡∞Æ‡∞æ‡∞ß‡∞æ‡∞®‡∞Ç ‡∞ö‡±Ü‡∞™‡±ç‡∞™‡∞°‡∞Ç‡∞≤‡±ã ‡∞∏‡∞Ç‡∞§‡±ã‡∞∑‡∞Ç, Deva! üòä \\n\\n‡∞è ‡∞™‡±ç‡∞∞‡∞∂‡±ç‡∞®‡∞≤‡±Å ‡∞â‡∞Ç‡∞ü‡±á ‡∞Ö‡∞°‡∞ø‡∞ó‡∞ø‡∞§‡±á ‡∞®‡±á‡∞®‡±Å ‡∞∏‡∞π‡∞æ‡∞Ø‡∞Ç ‡∞ö‡±á‡∞∏‡±ç‡∞§‡∞æ‡∞®‡±Å. \\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response =chain.invoke({\"language\":\"Telugu\",\"messages\":[HumanMessage(content=\"My name is Deva\")]})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡∞®‡∞æ‡∞ï‡±Å ‡∞Æ‡±Ä ‡∞™‡±á‡∞∞‡±Å ‡∞§‡±Ü‡∞≤‡∞ø‡∞Ø‡∞¶‡±Å. ‡∞Æ‡±Ä‡∞∞‡±Å ‡∞®‡∞æ‡∞§‡±ã ‡∞Æ‡±Ä ‡∞™‡±á‡∞∞‡±Å ‡∞ö‡±Ü‡∞™‡±ç‡∞™‡∞Ç‡∞°‡∞ø. üòä \\n'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = {\"configurable\":{\"session_id\":\"chat5\"}}\n",
    "response = with_message_history.invoke(\n",
    "    {'messages':[HumanMessage(content=\"What is my name?\")],\n",
    "     \"language\":\"Telugu\"},\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Managing conversation history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='what is 6-2', additional_kwargs={}, response_metadata={}),\n",
       " SystemMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " SystemMessage(content=\"you're welcome!\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='good', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage,trim_messages\n",
    "\n",
    "trimmer = trim_messages(\n",
    "    max_tokens = 30,\n",
    "    strategy=\"last\",\n",
    "    token_counter = model,\n",
    "    include_system = True,\n",
    "    allow_partial = False,\n",
    "    start_on = \"human\"\n",
    ")\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm bob\"),\n",
    "    SystemMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    SystemMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"what is 6-2\"),\n",
    "    SystemMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    SystemMessage(content=\"you're welcome!\"),\n",
    "    HumanMessage(content=\"good\")\n",
    "]\n",
    "\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You didn\\'t ask a question last. You said \"good\".  \\n\\nIs there anything I can help you with? üòä  \\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain=(\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\")|trimmer)\n",
    "    |prompt|model\n",
    ")\n",
    "\n",
    "response1=chain.invoke(\n",
    "    {\n",
    "    \"messages\":messages + [HumanMessage(content=\"What question did i ask last\")],\n",
    "    \"language\":\"English\"\n",
    "    }\n",
    ")\n",
    "\n",
    "response1.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## message history\n",
    "\n",
    "with_message_history = RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")\n",
    "\n",
    "config = {\"configurable\":{\"session_id\":\"chat6\"}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You asked \"What question did I ask last?\".  \\n\\nIs there anything else I can help you with? üòä \\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain=(\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\")|trimmer)\n",
    "    |prompt|model\n",
    ")\n",
    "\n",
    "response1=chain.invoke(\n",
    "    {\n",
    "    \"messages\":messages + [HumanMessage(content=\"What question did i ask last\")],\n",
    "    \"language\":\"English\"\n",
    "    }\n",
    ")\n",
    "\n",
    "response1.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
